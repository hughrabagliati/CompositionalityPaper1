length(p[abs(p) <= 0.05])
p <- rep(NA,1000)#
for (j in 1:length(p)){ #
subj_c1 = rep(NA,20)#
subj_c2 = rep(NA,20)#
for (i in 1:20){#
	subj_c1[i] <- mean(log(rlnorm(30,0,1)))#
	subj_c2[i] <- mean(log(rlnorm(30,0,1)))#
}#
p[j] <- t.test(subj_c1,subj_c2, paired = T, var.equal = T)$p.value#
}
<<<<<<< Updated upstream
perm$LargeSample[1:20]
OneSample <- q#
LargeSample <- matrix(NA, nrow = 10000, ncol = 1)#
#
perm = list(OneSample = OneSample,LargeSample = LargeSample)#
#
for (j in seq(1:10000)){#
a <- cbind(matrix(rnorm(24,0,2),12,2),1)#
#
=======
length(p[abs(p) <= 0.05])
p <- rep(NA,1000)#
for (j in 1:length(p)){ #
subj_c1 = rep(NA,20)#
subj_c2 = rep(NA,20)#
for (i in 1:20){#
	subj_c1[i] <- mean(log(rlnorm(30,0,1)))#
	subj_c2[i] <- mean(log(rlnorm(30,0,1)))#
}#
p[j] <- t.test(subj_c1,subj_c2, paired = T, var.equal = T)$p.value#
}
length(p[abs(p) <= 0.05])
p <- rep(NA,1000)#
for (j in 1:length(p)){ #
subj_c1 = rep(NA,20)#
subj_c2 = rep(NA,20)#
>>>>>>> Stashed changes
for (i in 1:20){#
	subj_c1[i] <- mean((rlnorm(30,0,1)))#
	subj_c2[i] <- mean((rlnorm(30,0,1)))#
}#
p[j] <- t.test(subj_c1,subj_c2, paired = T, var.equal = T)$p.value#
}
length(p[abs(p) <= 0.05])
p <- rep(NA,1000)#
for (j in 1:length(p)){ #
subj_c1 = rep(NA,20)#
subj_c2 = rep(NA,20)#
for (i in 1:20){#
	subj_c1[i] <- mean((rlnorm(30,0,1)))#
	subj_c2[i] <- mean((rlnorm(30,0,1)))#
}#
p[j] <- t.test(subj_c1,subj_c2, paired = T, var.equal = T)$p.value#
}
length(p[abs(p) <= 0.05])
p <- rep(NA,1000)#
for (j in 1:length(p)){ #
subj_c1 = rep(NA,20)#
subj_c2 = rep(NA,20)#
for (i in 1:20){#
	subj_c1[i] <- mean((rlnorm(30,0,1)))#
	subj_c2[i] <- mean((rlnorm(30,0,1)))#
}#
p[j] <- t.test(subj_c1,subj_c2, paired = T, var.equal = T)$p.value#
}
length(p[abs(p) <= 0.05])
p <- rep(NA,1000)#
for (j in 1:length(p)){ #
subj_c1 = rep(NA,20)#
subj_c2 = rep(NA,20)#
for (i in 1:20){#
	subj_c1[i] <- mean((rlnorm(30,0,1)))#
	subj_c2[i] <- mean((rlnorm(30,0,1)))#
}#
p[j] <- t.test(subj_c1,subj_c2, paired = T, var.equal = T)$p.value#
}
length(p[abs(p) <= 0.05])
p <- rep(NA,1000)#
for (j in 1:length(p)){ #
subj_c1 = rep(NA,20)#
subj_c2 = rep(NA,20)#
for (i in 1:20){#
	subj_c1[i] <- mean((rlnorm(30,0,1)))#
	subj_c2[i] <- mean((rlnorm(30,0,1)))#
}#
p[j] <- t.test(subj_c1,subj_c2, paired = T, var.equal = T)$p.value#
}
length(p[abs(p) <= 0.05])
hist(rlnorm(20,0,1))
hist(rlnorm(30,0,1))
hist(rlnorm(30,0,1.2))
hist(rlnorm(30,0,1.02))
p <- rep(NA,1000)#
for (j in 1:length(p)){ #
subj_c1 = rep(NA,20)#
subj_c2 = rep(NA,20)#
for (i in 1:20){#
	subj_c1[i] <- mean((rlnorm(30,0,1.02)))#
	subj_c2[i] <- mean((rlnorm(30,0,1.02)))#
}#
p[j] <- t.test(subj_c1,subj_c2, paired = T, var.equal = T)$p.value#
}
length(p[abs(p) <= 0.05])
p <- rep(NA,1000)#
for (j in 1:length(p)){ #
subj_c1 = rep(NA,20)#
subj_c2 = rep(NA,20)#
for (i in 1:20){#
	subj_c1[i] <- mean((rlnorm(30,0,1.2)))#
	subj_c2[i] <- mean((rlnorm(30,0,1.2)))#
}#
p[j] <- t.test(subj_c1,subj_c2, paired = T, var.equal = T)$p.value#
}
length(p[abs(p) <= 0.05])
p <- rep(NA,1000)#
for (j in 1:length(p)){ #
subj_c1 = rep(NA,20)#
subj_c2 = rep(NA,20)#
for (i in 1:20){#
	subj_c1[i] <- mean((rlnorm(20,0,1.2)))#
	subj_c2[i] <- mean((rlnorm(20,0,1.2)))#
}#
p[j] <- t.test(subj_c1,subj_c2, paired = T, var.equal = T)$p.value#
}
length(p[abs(p) <= 0.05])
p <- rep(NA,1000)#
for (j in 1:length(p)){ #
subj_c1 = rep(NA,20)#
subj_c2 = rep(NA,20)#
for (i in 1:20){#
	subj_c1[i] <- mean((rlnorm(20,0,1.2)))#
	subj_c2[i] <- mean((rlnorm(20,0,1.2)))#
}#
p[j] <- t.test(subj_c1,subj_c2, paired = T, var.equal = T)$p.value#
}
length(p[abs(p) <= 0.05])
p <- rep(NA,1000)#
for (j in 1:length(p)){ #
subj_c1 = rep(NA,20)#
subj_c2 = rep(NA,20)#
for (i in 1:20){#
	subj_c1[i] <- mean((rlnorm(20,0,1.2)))#
	subj_c2[i] <- mean((rlnorm(20,0,1.2)))#
}#
p[j] <- t.test(subj_c1,subj_c2, paired = F, var.equal = T)$p.value#
}
length(p[abs(p) <= 0.05])
p <- rep(NA,1000)#
for (j in 1:length(p)){ #
subj_c1 = rep(NA,20)#
subj_c2 = rep(NA,20)#
for (i in 1:20){#
	subj_c1[i] <- mean((rlnorm(20,0,1.2)))#
	subj_c2[i] <- mean((rlnorm(20,0,1.2)))#
}#
p[j] <- t.test(subj_c1,subj_c2, paired = F, var.equal = T)$p.value#
}
length(p[abs(p) <= 0.05])
p <- rep(NA,1000)#
for (j in 1:length(p)){ #
subj_c1 = rep(NA,20)#
subj_c2 = rep(NA,20)#
for (i in 1:20){#
	subj_c1[i] <- mean((rlnorm(20,0,1.2)))#
	subj_c2[i] <- mean((rlnorm(20,0,1.2)))#
}#
p[j] <- t.test(subj_c1,subj_c2, paired = F, var.equal = T)$p.value#
}
length(p[abs(p) <= 0.05])
p <- rep(NA,1000)#
for (j in 1:length(p)){ #
subj_c1 = rep(NA,20)#
subj_c2 = rep(NA,20)#
for (i in 1:20){#
	subj_c1[i] <- mean((rlnorm(20,0,1.2)))#
	subj_c2[i] <- mean((rlnorm(20,0,1.2)))#
}#
p[j] <- t.test(subj_c1,subj_c2, paired = F, var.equal = T)$p.value#
}
length(p[abs(p) <= 0.05])
p <- rep(NA,100000)#
for (j in 1:length(p)){ #
subj_c1 = rep(NA,20)#
subj_c2 = rep(NA,20)#
for (i in 1:20){#
	subj_c1[i] <- mean((rlnorm(20,0,1.2)))#
	subj_c2[i] <- mean((rlnorm(20,0,1.2)))#
}#
p[j] <- t.test(subj_c1,subj_c2, paired = F, var.equal = T)$p.value#
}
length(p[abs(p) <= 0.05])
length(p[abs(p) <= 0.05])/100000
p <- rep(NA,10000)#
for (j in 1:length(p)){ #
subj_c1 = rep(NA,20)#
subj_c2 = rep(NA,20)#
for (i in 1:30){#
	subj_c1[i] <- mean((rlnorm(20,0,1.2)))#
	subj_c2[i] <- mean((rlnorm(20,0,1.2)))#
}#
p[j] <- t.test(subj_c1,subj_c2, paired = T, var.equal = T)$p.value#
}
length(p[abs(p) <= 0.05])/10000
p <- rep(NA,10000)#
for (j in 1:length(p)){ #
subj_c1 = rep(NA,20)#
subj_c2 = rep(NA,20)#
for (i in 1:30){#
	subj_c1[i] <- mean((rlnorm(30,0,1.2)))#
	subj_c2[i] <- mean((rlnorm(30,0,1.2)))#
}#
p[j] <- t.test(subj_c1,subj_c2, paired = T, var.equal = T)$p.value#
}
length(p[abs(p) <= 0.05])/10000
length(p[abs(p) > 0.05])/10000
p <- rep(NA,10000)#
for (j in 1:length(p)){ #
subj_c1 = rep(NA,20)#
subj_c2 = rep(NA,20)#
for (i in 1:30){#
	subj_c1[i] <- mean((rlnorm(5,0,1.2)))#
	subj_c2[i] <- mean((rlnorm(5,0,1.2)))#
}#
p[j] <- t.test(subj_c1,subj_c2, paired = T, var.equal = T)$p.value#
}
length(p[abs(p) > 0.05])/10000
p <- rep(NA,10000)#
for (j in 1:length(p)){ #
subj_c1 = rep(NA,20)#
subj_c2 = rep(NA,20)#
for (i in 1:30){#
	subj_c1[i] <- mean((rlnorm(1,0,1.2)))#
	subj_c2[i] <- mean((rlnorm(1,0,1.2)))#
}#
p[j] <- t.test(subj_c1,subj_c2, paired = T, var.equal = T)$p.value#
}
length(p[abs(p) > 0.05])/10000
p <- rep(NA,10000)#
for (j in 1:length(p)){ #
subj_c1 = rep(NA,20)#
subj_c2 = rep(NA,20)#
for (i in 1:30){#
	subj_c1[i] <- mean((rlnorm(100,0,1.2)))#
	subj_c2[i] <- mean((rlnorm(100,0,1.2)))#
}#
p[j] <- t.test(subj_c1,subj_c2, paired = T, var.equal = T)$p.value#
}
length(p[abs(p) > 0.05])/10000
subj_c1
subj_c2
?rlnorm
p <- rep(NA,1000)#
for (j in 1:length(p)){ #
subj_c1 = rep(NA,20)#
subj_c2 = rep(NA,20)#
for (i in 1:30){#
	subj_c1[i] <- mean((rlnorm(30,0,0.5)))#
	subj_c2[i] <- mean((rlnorm(30,0,0,5)))#
}#
p[j] <- t.test(subj_c1,subj_c2, paired = T, var.equal = T)$p.value#
}
p <- rep(NA,1000)#
for (j in 1:length(p)){ #
subj_c1 = rep(NA,20)#
subj_c2 = rep(NA,20)#
for (i in 1:30){#
	subj_c1[i] <- mean((rlnorm(30,0,0.5)))#
	subj_c2[i] <- mean((rlnorm(30,0,0.5)))#
}#
p[j] <- t.test(subj_c1,subj_c2, paired = T, var.equal = T)$p.value#
}
length(p[abs(p) > 0.05])/1000
p <- rep(NA,1000)#
for (j in 1:length(p)){ #
subj_c1 = rep(NA,20)#
subj_c2 = rep(NA,20)#
for (i in 1:30){#
	subj_c1[i] <- mean((rlnorm(30,0,0.5)))#
	subj_c2[i] <- mean((rlnorm(30,0,0.5)))#
}#
p[j] <- t.test(subj_c1,subj_c2, paired = T, var.equal = T)$p.value#
}
length(p[abs(p) > 0.05])/1000
hist(subj_c1)
hist(subj_c2)
p[j]
t.test(subj_c1,subj_c2, paired = T, var.equal = T)
t.test(subj_c1,subj_c2, paired = F, var.equal = F)
hist(rlnorm(100,1,0.5))
p <- rep(NA,1000)#
for (j in 1:length(p)){ #
subj_c1 = rep(NA,20)#
subj_c2 = rep(NA,20)#
for (i in 1:30){#
	subj_c1[i] <- mean((rlnorm(100,1,0.5)))#
	subj_c2[i] <- mean((rlnorm(100,1,0.5)))#
}#
p[j] <- t.test(subj_c1,subj_c2, paired = T, var.equal = T)$p.value#
}
length(p[abs(p) > 0.05])/1000
length(p[abs(p) <= 0.05])/1000
p <- rep(NA,1000)#
for (j in 1:length(p)){ #
subj_c1 = rep(NA,20)#
subj_c2 = rep(NA,20)#
for (i in 1:30){#
	subj_c1[i] <- mean((rlnorm(25,1,0.5)))#
	subj_c2[i] <- mean((rlnorm(25,1,0.5)))#
}#
p[j] <- t.test(subj_c1,subj_c2, paired = T, var.equal = T)$p.value#
}
length(p[abs(p) <= 0.05])/1000
p <- rep(NA,1000)#
for (j in 1:length(p)){ #
subj_c1 = rep(NA,20)#
subj_c2 = rep(NA,20)#
for (i in 1:30){#
	subj_c1[i] <- mean((rlnorm(25,1,0.5)))#
	subj_c2[i] <- mean((rlnorm(25,1,0.5)))#
}#
p[j] <- t.test(subj_c1,subj_c2, paired = T, var.equal = T)$p.value#
}
length(p[abs(p) <= 0.05])/1000
p <- rep(NA,1000)#
for (j in 1:length(p)){ #
subj_c1 = rep(NA,20)#
subj_c2 = rep(NA,20)#
for (i in 1:30){#
	subj_c1[i] <- mean((rlnorm(25,1,0.5)))#
	subj_c2[i] <- mean((rlnorm(25,1,0.5)))#
}#
p[j] <- t.test(subj_c1,subj_c2, paired = T, var.equal = T)$p.value#
}
length(p[abs(p) <= 0.05])/1000
p <- rep(NA,1000)#
for (j in 1:length(p)){ #
subj_c1 = rep(NA,20)#
subj_c2 = rep(NA,20)#
for (i in 1:30){#
	subj_c1[i] <- mean((rlnorm(25,1,0.5)))#
	subj_c2[i] <- mean((rlnorm(25,1,0.5)))#
}#
p[j] <- t.test(subj_c1,subj_c2, paired = T, var.equal = T)$p.value#
}
length(p[abs(p) <= 0.05])/1000
a <- c()"boats", "houses", "lamps", "stars", "discs", "planes" , "bags", "locks", "canes", "hands", "shoes", "bones", "squares", "bells", "bows", "cars", "crosses", "cups", "flags", "forks" "hearts", "leaves", "trees","bikes","chairs","toys","coin","keys","clocks","pumps","shells","houses","hats","planes","dolls","spoons","forks","beds","beetles","cups","bowls","bags","buckets","dogs","geese","cats","cans","hammers","bricks","bottles","pens","pencils","ribbons","cards","buttons","rings","dice","shirts","socks","shoes","belts","bells","flowers","pots","eagles","frogs")
a <- c("boats", "houses", "lamps", "stars", "discs", "planes" , "bags", "locks", "canes", "hands", "shoes", "bones", "squares", "bells", "bows", "cars", "crosses", "cups", "flags", "forks" "hearts", "leaves", "trees","bikes","chairs","toys","coin","keys","clocks","pumps","shells","houses","hats","planes","dolls","spoons","forks","beds","beetles","cups","bowls","bags","buckets","dogs","geese","cats","cans","hammers","bricks","bottles","pens","pencils","ribbons","cards","buttons","rings","dice","shirts","socks","shoes","belts","bells","flowers","pots","eagles","frogs")
a <- c("boats", "houses", "lamps", "stars", "discs", "planes" , "bags", "locks", "canes", "hands", "shoes", "bones", "squares", "bells", "bows", "cars", "crosses", "cups", "flags", "forks" "hearts", "leaves","trees","bikes","chairs","toys","coin","keys","clocks","pumps","shells","houses","hats","planes","dolls","spoons","forks","beds","beetles","cups","bowls","bags","buckets","dogs","geese","cats","cans","hammers","bricks","bottles","pens","pencils","ribbons","cards","buttons","rings","dice","shirts","socks","shoes","belts","bells","flowers","pots","eagles","frogs")
a <- c("boats", "houses", "lamps", "stars", "discs", "planes" , "bags", "locks", "canes", "hands", "shoes", "bones", "squares", "bells", "bows", "cars", "crosses", "cups", "flags", "forks",leaves","trees","bikes","chairs","toys","coin","keys","clocks","pumps","shells","houses","hats","planes","dolls","spoons","forks","beds","beetles","cups","bowls","bags","buckets","dogs","geese","cats","cans","hammers","bricks","bottles","pens","pencils","ribbons","cards","buttons","rings","dice","shirts","socks","shoes","belts","bells","flowers","pots","eagles","frogs")
a = c("boats", "houses", "lamps", "stars", "discs", "planes" , "bags", "locks", "canes", "hands", "shoes", "bones", "squares", "bells", "bows", "cars", "crosses", "cups", "flags", "forks" ,"hearts", "leaves", "trees","bikes","chairs","toys","coin","keys","clocks","pumps","shells","houses","hats","planes","dolls","spoons","forks","beds","beetles","cups","bowls","bags","buckets","dogs","geese","cats","cans","hammers","bricks","bottles","pens","pencils","ribbons","cards","buttons","rings","dice","shirts","socks","shoes","belts","bells","flowers","pots","eagles","frogs")
length(a)
unique(a)
length(unique(a))
summary(a)
summary(as.factor(a))
?aspell
aspell(a)
a = c("boats", "houses", "lamps", "stars", "discs", "planes" , "bags", "locks", "canes", "hands", "shoes", "bones", "squares", "bells", "bows", "cars", "crosses", "flags", "hearts", "leaves", "trees","bikes","chairs","toys","coin","keys","clocks","pumps","shells","houses","hats","planes","dolls","spoons","forks","beds","beetles","cups","bowls","bags","buckets","dogs","geese","cats","cans","hammers","bricks","bottles","pens","pencils","ribbons","cards","buttons","rings","dice","shirts","socks","belts","flowers","pots","eagles","frogs","combs","candies","trays","pipes","baskets","cushions","blankets","towels","cans","tubes","monkeys","napkins","crates","pills","rocks","ropes","sticks","wheels","boots","cones","squares","triangle","puppets")
length(a)
a <- c("boats", "houses", "lamps", "stars", "discs", "planes" , "bags", "locks", "canes", "hands", "shoes", "bones", "squares", "bells", "bows", "cars", "crosses", "flags", "hearts", "leaves", "trees","bikes","chairs","toys","coin","keys","clocks","pumps","shells","houses","hats","planes","dolls","spoons","forks","beds","beetles","cups","bowls","bags","buckets","dogs","geese","cats","cans","hammers","bricks","bottles","pens","pencils","ribbons","cards","buttons","rings","dice","shirts","socks","belts","flowers","pots","eagles","frogs","combs","candies","trays","pipes","baskets","cushions","blankets","towels","cans","tubes","monkeys","napkins","crates","pills","rocks","ropes","sticks","wheels","boots","cones","squares","triangle","puppets","violins","barrels","gloves","erasers","beans","rings","pillows","candles","mugs","books")
length(a)
length(unique(a))
a <- c("boats", "houses", "lamps", "stars", "discs", "planes" , "bags", "locks", "canes", "hands", "shoes", "bones", "squares", "bells", "bows", "cars", "crosses", "flags", "hearts", "leaves", "trees","bikes","chairs","toys","coin","keys","clocks","pumps","shells","houses","hats","planes","dolls","spoons","forks","beds","beetles","cups","bowls","bags","buckets","dogs","geese","cats","cans","hammers","bricks","bottles","pens","pencils","ribbons","cards","buttons","rings","dice","shirts","socks","belts","flowers","pots","eagles","frogs","combs","candies","trays","pipes","baskets","cushions","blankets","towels","cans","tubes","monkeys","napkins","crates","pills","rocks","ropes","sticks","wheels","boots","cones","squares","triangle","puppets","violins","barrels","gloves","erasers","beans","rings","pillows","candles","mugs","books","toys","balloons",)
a <- c("boats", "houses", "lamps", "stars", "discs", "planes" , "bags", "locks", "canes", "hands", "shoes", "bones", "squares", "bells", "bows", "cars", "crosses", "flags", "hearts", "leaves", "trees","bikes","chairs","toys","coin","keys","clocks","pumps","shells","houses","hats","planes","dolls","spoons","forks","beds","beetles","cups","bowls","bags","buckets","dogs","geese","cats","cans","hammers","bricks","bottles","pens","pencils","ribbons","cards","buttons","rings","dice","shirts","socks","belts","flowers","pots","eagles","frogs","combs","candies","trays","pipes","baskets","cushions","blankets","towels","cans","tubes","monkeys","napkins","crates","pills","rocks","ropes","sticks","wheels","boots","cones","squares","triangle","puppets","violins","barrels","gloves","erasers","beans","rings","pillows","candles","mugs","books","toys","balloons")
length(unique(a))
summary(as.factor(a))
a <- c("boats", "houses", "lamps", "stars", "discs", "planes" , "locks", "canes", "hands", "shoes", "bones", "squares", "bells", "bows", "cars", "crosses", "flags", "hearts", "leaves", "trees","bikes","chairs","coin","keys","clocks","pumps","shells","hats","planes","dolls","spoons","forks","beds","beetles","cups","bowls","bags","buckets","dogs","geese","cats","cans","hammers","bricks","bottles","pens","pencils","ribbons","cards","buttons","dice","shirts","socks","belts","flowers","pots","eagles","frogs","combs","candies","trays","pipes","baskets","cushions","blankets","towels","tubes","monkeys","napkins","crates","pills","rocks","ropes","sticks","wheels","boots","cones","squares","triangle","puppets","violins","barrels","gloves","erasers","beans","rings","pillows","candles","mugs","books","toys","balloons")
length(unique(a))
length(a)
summary(as.factor(a))
a <- c("boats", "houses", "lamps", "stars", "discs", "planes" , "locks", "canes", "hands", "shoes", "bones", "squares", "bells", "bows", "cars", "crosses", "flags", "hearts", "leaves", "trees","bikes","chairs","coin","keys","clocks","pumps","shells","hats","dolls","spoons","forks","beds","beetles","cups","bowls","bags","buckets","dogs","geese","cats","cans","hammers","bricks","bottles","pens","pencils","ribbons","cards","buttons","dice","shirts","socks","belts","flowers","pots","eagles","frogs","combs","candies","trays","pipes","baskets","cushions","blankets","towels","tubes","monkeys","napkins","crates","pills","rocks","ropes","sticks","wheels","boots","cones","triangle","puppets","violins","barrels","gloves","erasers","beans","rings","pillows","candles","mugs","books","toys","balloons","clocks","letters","parcels","slippers")
length(a)
length(unique(a))
summary(as.factor(a))
a <- c("boats", "houses", "lamps", "stars", "discs", "planes" , "locks", "canes", "hands", "shoes", "bones", "squares", "bells", "bows", "cars", "crosses", "flags", "hearts", "leaves", "trees","bikes","chairs","coin","keys","clocks","pumps","shells","hats","dolls","spoons","forks","beds","beetles","cups","bowls","bags","buckets","dogs","geese","cats","cans","hammers","bricks","bottles","pens","pencils","ribbons","cards","buttons","dice","shirts","socks","belts","flowers","pots","eagles","frogs","combs","candies","trays","pipes","baskets","cushions","blankets","towels","tubes","monkeys","napkins","crates","pills","rocks","ropes","sticks","wheels","boots","cones","triangle","puppets","violins","barrels","gloves","erasers","beans","rings","pillows","candles","mugs","books","toys","balloons","letters","parcels","slippers","masks","shells")
length(unique(a))
length(a)
summary(as.factor(a))
a <- c("boats", "houses", "lamps", "stars", "discs", "planes" , "locks", "canes", "hands", "shoes", "bones", "squares", "bells", "bows", "cars", "crosses", "flags", "hearts", "leaves", "trees","bikes","chairs","coin","keys","clocks","pumps","shells","hats","dolls","spoons","forks","beds","beetles","cups","bowls","bags","buckets","dogs","geese","cats","cans","hammers","bricks","bottles","pens","pencils","ribbons","cards","buttons","dice","shirts","socks","belts","flowers","pots","eagles","frogs","combs","candies","trays","pipes","baskets","cushions","blankets","towels","tubes","monkeys","napkins","crates","pills","rocks","ropes","sticks","wheels","boots","cones","triangle","puppets","violins","barrels","gloves","erasers","beans","rings","pillows","candles","mugs","books","toys","balloons","letters","parcels","slippers","masks","seeds","cookies","dishes","drums","carrots")
summary(as.factor(a))
length(unique(a))
length(a)
a <- c(""boats", "houses", "lamps", "stars", "discs", "planes" , "locks", "canes", "hands", "shoes", "bones", "squares", "bells", "bows", "cars", "crosses", "flags", "hearts", "leaves", "trees","bikes","chairs","coin","keys","clocks","pumps","shells","hats","dolls","spoons","forks","beds","beetles","cups","bowls","bags","buckets","dogs","geese","cats","cans","hammers","bricks","bottles","pens","pencils","ribbons","cards","buttons","dice","shirts","socks","belts","flowers","pots","eagles","frogs","combs","candies","trays","pipes","baskets","cushions","blankets","towels","tubes","monkeys","napkins","crates","pills","rocks","ropes","sticks","wheels","boots","cones","triangle","puppets","violins","barrels","gloves","erasers","beans","rings","pillows","candles","mugs","books","toys","balloons","letters","parcels","slippers","masks","seeds","cookies","dishes","drums","carrots","peppers"")
a <- c("boats", "houses", "lamps", "stars", "discs", "planes" , "locks", "canes", "hands", "shoes", "bones", "squares", "bells", "bows", "cars", "crosses", "flags", "hearts", "leaves", "trees","bikes","chairs","coin","keys","clocks","pumps","shells","hats","dolls","spoons","forks","beds","beetles","cups","bowls","bags","buckets","dogs","geese","cats","cans","hammers","bricks","bottles","pens","pencils","ribbons","cards","buttons","dice","shirts","socks","belts","flowers","pots","eagles","frogs","combs","candies","trays","pipes","baskets","cushions","blankets","towels","tubes","monkeys","napkins","crates","pills","rocks","ropes","sticks","wheels","boots","cones","triangle","puppets","violins","barrels","gloves","erasers","beans","rings","pillows","candles","mugs","books","toys","balloons","letters","parcels","slippers","masks","seeds","cookies","dishes","drums","carrots","peppers")
length(a)
length(unique(a))
library(lme4)
inv(-3)
1/-1.3
library(retimes)
rexgauss(5,0,1,1)
hist(rexgauss(50,0,1,0.5))
rexgauss(50,0,1,1)
help('stan')
library(stan)
library(rstan)
help(stan)
1/10
1/2
exp(0.1)
?exp
0.1/1
1/0.1
1/0.5
library(retimes)
curve(dexGAUS(x, mu=300 ,sigma=35,nu=100), 100, 600, #
 main = "The ex-GAUS  density mu=300 ,sigma=35,nu=100")#
curve(dexGAUS(x, mu=300 ,sigma=35,nu=300), 100, 600,add = T, #
 main = "The ex-GAUS  density mu=300 ,sigma=35,nu=100")
plot(0, )
plot(1, type="n", axes=F, xlab="", ylab="")
curve(dexGAUS(x, mu=300 ,sigma=35,nu=100), 100, 600, #
 main = "The ex-GAUS  density mu=300 ,sigma=35,nu=100")#
curve(dexGAUS(x, mu=300 ,sigma=35,nu=300), 100, 600,add = T, #
 main = "The ex-GAUS  density mu=300 ,sigma=35,nu=100")
library(gamlss.dist)
curve(dexGAUS(x, mu=300 ,sigma=35,nu=100), 100, 600, #
 main = "The ex-GAUS  density mu=300 ,sigma=35,nu=100")#
curve(dexGAUS(x, mu=300 ,sigma=35,nu=300), 100, 600,add = T, #
 main = "The ex-GAUS  density mu=300 ,sigma=35,nu=100")
library(gamlss.dist)
curve(dexGAUS(x, mu=300 ,sigma=35,nu=100), 100, 600, #
 main = "The ex-GAUS  density mu=300 ,sigma=35,nu=100")#
curve(dexGAUS(x, mu=300 ,sigma=35,nu=300), 100, 600,add = T, #
 main = "The ex-GAUS  density mu=300 ,sigma=35,nu=100")
curve(dexGAUS(x, mu=300 ,sigma=35,nu=100), 100, 600, #
 main = "")#
curve(dexGAUS(x, mu=300 ,sigma=35,nu=300), 100, 600,add = T, #
 main = "", col = "red")
curve(dexGAUS(x, mu=300 ,sigma=35,nu=100), 100, 600, #
 main = "", lwd = 5)#
curve(dexGAUS(x, mu=300 ,sigma=35,nu=300), 100, 600,add = T, #
 main = "", col = "red", lwd = 5)
curve(dexGAUS(x, mu=300 ,sigma=35,nu=100), 100, 600, #
 main = "", lwd = 5, ylab = "Prob. Density", xlab  = "reaction time")#
curve(dexGAUS(x, mu=300 ,sigma=35,nu=300), 100, 600,add = T, #
 main = "", col = "red", lwd = 5)
curve(dexGAUS(x, mu=300 ,sigma=35,nu=100), 100, 600, #
 main = "", lwd = 5, ylab = "Prob. Density", xlab  = "Reaction Time")#
curve(dexGAUS(x, mu=300 ,sigma=35,nu=300), 100, 600,add = T, #
 main = "", col = "red", lwd = 5)
curve(dexGAUS(x, mu=300 ,sigma=35,nu=100), 100, 600, #
 main = "", lwd = 5, ylab = "Prob. Density", xlab  = "Reaction Time", bty = "n")#
curve(dexGAUS(x, mu=300 ,sigma=35,nu=300), 100, 600,add = T, #
 main = "", col = "red", lwd = 5)
curve(dexGAUS(x, mu=300 ,sigma=35,nu=100), 100, 600, #
 main = "", lwd = 5, ylab = "Prob. Density", xlab  = "Reaction Time", bty = "n")#
curve(dexGAUS(x, mu=400 ,sigma=35,nu=100), 100, 600,add = T, #
 main = "", col = "red", lwd = 5)
curve(dexGAUS(x, mu=300 ,sigma=35,nu=100), 100, 600, #
 main = "", lwd = 5, ylab = "Prob. Density", xlab  = "Reaction Time", bty = "n")
curve(dexGAUS(x, mu=300 ,sigma=35,nu=300), 100, 600, #
 main = "", lwd = 5, ylab = "Prob. Density", xlab  = "Reaction Time", bty = "n")
curve(dexGAUS(x, mu=300 ,sigma=35,nu=300), 300, 1500, #
 main = "", lwd = 5, ylab = "Prob. Density", xlab  = "Reaction Time", bty = "n")
curve(dexGAUS(x, mu=300 ,sigma=35,nu=300), 200, 1500, #
 main = "", lwd = 5, ylab = "Prob. Density", xlab  = "Reaction Time", bty = "n")
library(reshape2)#
library(ggplot2)#
library(gridExtra)#
library(grid)#
library(jsonlite)#
library(ez)#
# This script is used to read in all the csv files in a folder.#
#
library(doBy)#
## for bootstrapping 95% confidence intervals -- from Mike Frank https://github.com/langcog/KTE/blob/master/mcf.useful.R#
library(bootstrap)#
theta <- function(x,xdata,na.rm=T) {mean(xdata[x],na.rm=na.rm)}#
ci.low <- function(x,na.rm=T) {#
  quantile(bootstrap(1:length(x),1000,theta,x,na.rm=na.rm)$thetastar,.025,na.rm=na.rm)} #  mean(x,na.rm=na.rm) -#
ci.high <- function(x,na.rm=T) {#
  quantile(bootstrap(1:length(x),1000,theta,x,na.rm=na.rm)$thetastar,.975,na.rm=na.rm) } #- mean(x,na.rm=na.rm)}#
#
Catch_Import= function(path_name){#
  library(jsonlite)#
  list.files(path = path_name,full.names = T, pattern = ".txt") -> file_list#
  comp = c()#
  for (x in file_list){#
    file_name = x#
    df <- fromJSON(file_name)#
    d <- df$data$trialdata[1:2,]   ##df$data[4]$trialdata$key_press %in% c(71,32),]#
    d$Subj <- unique(df$data$trialdata[df$data$trialdata$Screen == "Real-Response",]$Subj)[2]#
    output <- cbind(key = d$key_press,Subj = d$Subj)#
    comp = rbind(comp,output)#
    print(x)#
  }#
  return(comp)#
}#
Comp_Import = function(path_name){#
  library(jsonlite)#
  list.files(path = path_name,full.names = T, pattern = ".txt") -> file_list#
  comp = c()#
  for (x in file_list){#
    file_name = x#
    df <- fromJSON(file_name)#
    d <- df$data$trialdata[df$data$trialdata$Screen == "Real-Response",]#
    d <- d[d$stims$Cond %in% c("Mismatch-Mask-List","Mismatch-List","Mismatch-Mask-Adj", "Mismatch-Color", "Mismatch-Noun" ,"Match-Mask-List","Match-List","Match-Mask-Adj", "Match-Adj"),]#
    #d <- d[d$stims$Cond %in% c("Match-Mask-List","Match-List","Match-Mask-Adj", "Match-Adj" ),]#
    d$Cond <- as.factor(d$stims$Cond)#
    d$Item <- as.factor(d$stims$Item)#
    d$Task <- "List"#
    d[d$Cond %in% c("Match-Adj", "Match-Mask-Adj","Mismatch-Mask-Adj", "Mismatch-Color", "Mismatch-Noun" ),]$Task <- "Phrase"#
    d$Task <- as.factor(d$Task)#
    d$Stim <- "One Word"#
    d[d$Cond %in% c("Match-Adj", "Match-List","Mismatch-List","Mismatch-Color", "Mismatch-Noun"),]$Stim <- "Two Words"#
    d$Stim <- ordered(d$Stim, levels = c("One Word", "Two Words"))#
    d$Match <- "Match"#
    d[d$stims$Cond %in% c("Mismatch-Mask-List","Mismatch-List","Mismatch-Mask-Adj", "Mismatch-Color", "Mismatch-Noun"),]$Match <- "MisMatch"#
    d$Match <- as.factor(d$Match)#
    output <- data.frame(rt = as.numeric(as.character(d$rt)), key_press = d$key_press, Subj = d$Subj, Item = d$Item, Cond = d$Cond, Task = d$Task, Stim = d$Stim, Match = d$Match)#
    output$rt <- as.numeric(as.character(output$rt))#
    comp = rbind(comp,output)#
    print(x)#
  }#
  return(comp)#
}#
#
# Function for plotting data using bar plots#
Comp_Graph = function(DV.mean, DV.se, IV1, IV2, Subj, title,ylimit,ylab,leg = FALSE){#
  DV.se <- DV.se/(sqrt( (length(unique(Subj))) ))#
  comp.graph.mean <- tapply(DV.mean,list(IV1, IV2), mean)#
  comp.graph.se <- tapply(DV.se,list(IV1, IV2), mean)#
  if (leg == TRUE){#
    x <- barplot(comp.graph.mean, beside = T, ylim = ylimit, ylab = ylab, legend = T, xpd = FALSE, names.arg = c("Composition Task\nPink Tree","List Task\nCup, Tree"),  col = c("gray47"), density = c(40,100), args.legend = list(bty = "n", x = 5), tck = -0.01)#
  } else{#
    x <- barplot(comp.graph.mean, beside = T, ylim = ylimit, ylab = ylab,  legend = F, xpd = FALSE, names.arg = c("Composition Task\nPink Tree","List Task\nCup Tree"),   col = c("gray47"), density = c(40,100), tick = FALSE, axes = FALSE)#
    axis(2, at = c(0.5,0.75,1), labels = c(0.5,0.75,1.0), tck = -0.03)#
  }#
  arrows(x, (c(comp.graph.mean) + c(comp.graph.se)+0.01), x, (c(comp.graph.mean) - c(comp.graph.se)-0.01), code = 0)#
}#
library(lme4)#
catch <- Catch_Import("./Exp1a")#
print(catch)#
comp <- Comp_Import("./Exp1a")#
contrasts(comp$Stim) <- c(-0.5,0.5)#
contrasts(comp$Task) <- c(-0.5,0.5)#
comp <- comp[comp$rt > 300 & comp$rt <1500,]#
comp$Acc <- 0#
comp[comp$key_press == 77 & comp$Match == "Match",]$Acc <- 1#
comp[comp$key_press == 90 & comp$Match == "MisMatch",]$Acc <- 1#
comp$Task <- factor(comp$Task, levels(comp$Task)[c(2,1)])#
#
# Calcs for within subj SEs#
comp$rtAdj <- NA#
comp$AccAdj <- NA#
for (i in unique(comp$Subj)){#
  comp[comp$Subj == i,]$rtAdj <- ((comp[comp$Subj == i,]$rt - mean(comp[comp$Subj == i,]$rt, na.rm = T)) + mean(comp$rt, na.rm = T))#
  comp[comp$Subj == i,]$AccAdj <- ((comp[comp$Subj == i,]$Acc - mean(comp[comp$Subj == i,]$Acc, na.rm = T)) + mean(comp$Acc, na.rm = T))#
}#
#
comp$base_item <- as.factor(colsplit(comp$Item,"_",names = c("word1","word2"))[,2])#
contrasts(comp$Stim)[1] <- -1#
contrasts(comp$Task)[1] <- -1#
contrasts(comp$Stim)[2] <- 1#
contrasts(comp$Task)[2] <- 1#
# RT Analyses#
#
lmer(rt ~ Stim * Task + (1+Stim*Task|Subj)+ (1+Stim*Task|base_item) , data = subset(comp, Acc ==1 & Match == "Match")) -> exp1a.full#
lmer(rt ~ Stim + Task + (1+Stim*Task|Subj)+ (1+Stim*Task|base_item) , data = subset(comp, Acc ==1 & Match == "Match")) -> exp1a.noint#
anova(exp1a.full, exp1a.noint)#
#
# Stim removed for convergence#
lmer(rt ~ Stim  +  (1+Stim|Subj)+ (1|base_item) , data = subset(comp, Acc ==1 & Match == "Match" & Task == "Phrase")) -> exp1a.full.phrase#
lmer(rt ~ 1 + (1+Stim|Subj)+ (1|base_item) , data = subset(comp, Acc ==1 & Match == "Match" & Task == "Phrase")) -> exp1a.noint.phrase#
anova(exp1a.full.phrase, exp1a.noint.phrase)#
#
lmer(rt ~ Stim  + (1+Stim|Subj)+ (1|base_item) , data = subset(comp, Acc ==1 & Match == "Match" & Task != "Phrase")) -> exp1a.full.nophrase#
lmer(rt ~ 1 + (1+Stim|Subj)+ (1|base_item) , data = subset(comp, Acc ==1 & Match == "Match" & Task != "Phrase")) -> exp1a.noint.nophrase#
anova(exp1a.full.nophrase, exp1a.noint.nophrase)#
#
ezANOVA(subset(comp, Acc ==1 & Match == "Match" ), rt, wid = .(Subj), within = .(Stim, Task))$ANOVA#
ezANOVA(subset(comp, Acc ==1 & Match == "Match" & Task == "List"), rt, wid = .(Subj), within = .(Stim))$ANOVA#
ezANOVA(subset(comp, Acc ==1 & Match == "Match" & Task != "List"), rt, wid = .(Subj), within = .(Stim))$ANOVA#
# Acc Analyses#
ezANOVA(comp, Acc, wid = .(Subj), within = .(Stim,Task))$ANOVA#
#
# GLMER Analysis, Lots of RanEf removed for convergence#
glmer(Acc ~ Stim * Task + (1+Stim + Task|Subj) , data = comp, family = "binomial") -> exp1a.acc.full#
glmer(Acc ~ Stim + Task + (1+Stim+ Task|Subj) , data = comp, family = "binomial") -> exp1a.acc.noint#
anova(exp1a.acc.full, exp1a.acc.noint)#
#
# Prepare variables for bar graph#
comp$DetailedTask <- "List (Cup,Tree)"#
comp[comp$Task == "Phrase",]$DetailedTask <- "Phrase (Pink Tree)"#
comp$DetailedTask <- ordered(comp$DetailedTask, levels = c("Phrase (Pink Tree)", "List (Cup,Tree)"))#
comp$Stim <- ordered(comp$Stim, levels = c("Two Words", "One Word"))#
#
comp.rt <- summaryBy(rt + rtAdj ~ DetailedTask + Stim  + Subj, , data = subset(comp, Acc ==1 & Match == "Match"), FUN = c(mean), na.rm = T , keep.names = T)#
comp.rt <- summaryBy(rt + rtAdj ~ DetailedTask + Stim  , data = comp.rt, FUN = c(mean,sd), na.rm = T )#
print(comp.rt)#
#
comp.Acc <- summaryBy(Acc + AccAdj~  DetailedTask + Stim  +Subj, , data = comp, FUN = c(mean), na.rm = T , keep.names = T)#
comp.Acc <- summaryBy(Acc + AccAdj~  DetailedTask + Stim   , data = comp, FUN = c(mean,sd), na.rm = T )#
print(comp.Acc)#
#
par(fig = c(0,1,0.35,1),mar = c(3,4,2,2))#
Comp_Graph(comp.rt$rt.mean,comp.rt$rtAdj.sd, comp.rt$Stim, comp.rt$DetailedTask, comp$Subj, paste("Two Words", "Reaction Time", sep = " "), c(700,1000),"Reaction Time (ms)",leg = TRUE)#
par(fig = c(0,1,0,0.35),mar = c(3,4,2,2), new = TRUE)#
Comp_Graph(comp.Acc$Acc.mean,comp.Acc$AccAdj.sd, comp.Acc$Stim, comp.Acc$DetailedTask, comp$Subj, paste("Two Words", "Accuracy", sep = " "), c(0.5,1),"Accuracy")#
#
# Prepare variables for bar graph#
comp$DetailedTask <- ordered(comp$DetailedTask, levels = c("Phrase (Pink Tree)","List (Cup,Tree)"))#
comp$Stim <- ordered(comp$Stim, levels = c("One Word", "Two Words"))#
#
comp.rt <- summaryBy(rt + rtAdj ~ DetailedTask + Stim  + Subj, , data = subset(comp, Acc ==1 & Match == "Match"), FUN = c(mean), na.rm = T , keep.names = T)#
# Print RT means and c.i.s#
ci.m <- aggregate(rt ~  Stim + DetailedTask , comp.rt, mean); ci.m#
ci.l <- aggregate(rt ~  Stim + DetailedTask , comp.rt, ci.low); ci.l#
ci.h <- aggregate(rt ~  Stim + DetailedTask , comp.rt, ci.high); ci.h#
#
comp.rt <- summaryBy(rt + rtAdj ~ DetailedTask + Stim  , data = comp.rt, FUN = c(mean,sd), na.rm = T )#
comp.Acc <- summaryBy(Acc + AccAdj~  DetailedTask + Stim  +Subj, , data = comp, FUN = c(mean), na.rm = T , keep.names = T)#
comp.Acc <- summaryBy(Acc + AccAdj~  DetailedTask + Stim   , data = comp, FUN = c(mean,sd), na.rm = T )#
#
# Function for plotting data as a ling graph#
Comp_Graph_l = function(DV.mean, DV.se, IV1, IV2, Subj, title,ylimit,ylab,leg = FALSE){#
  theme_set(theme_bw())#
  DV.se <- DV.se/(sqrt(length(unique(Subj))))#
  #comp.graph.mean <- tapply(DV.mean,list(IV1, IV2), mean)#
  #comp.graph.se <- tapply(DV.se,list(IV1, IV2), mean)#
  graph_data <- data.frame(Stim = IV1, Task = IV2, DV = DV.mean, SE = DV.se)#
  print((graph_data))#
  if (leg == TRUE){#
    #x <- barplot(comp.graph.mean, beside = T, ylim = ylimit, ylab = ylab, legend = T, xpd = FALSE, names.arg = c("Composition Task\nPink Tree","List Task\nCup, Tree"),  col = c("gray47"), density = c(40,100), args.legend = list(bty = "n", x = 2.8), tck = -0.01)#
    # PRetty ggplot2 code drawn from https://github.com/langcog/KTE/blob/master/full%20analysis%20all%20experiments.R#
    #		#
    x <- ggplot(graph_data, aes(x=Stim, y=DV,group = Task, linetype = Task)) + #
      ylim(ylimit) +#
      ylab(ylab) +#
      geom_line(aes(group = Task, linetype = Task),position=position_dodge(width=.1),stat="identity") + #
      geom_linerange(aes(ymin=DV - SE, ymax=DV + SE), position=position_dodge(width=.1))+ #
      guides(colour=guide_legend()) +#
      theme(strip.background = element_rect(fill="#FFFFFF"), #
            strip.text = element_text(size=12), #
            axis.text = element_text(size=12),#
            axis.title = element_text(size=14),#
            legend.text = element_text(size=12),#
            legend.key = element_blank(),#
            legend.title=element_blank(),#
            title = element_text(size=16),#
            panel.grid = element_blank(),#
            axis.title.x=element_blank(),#
            legend.position=c(0.3,0.8))#
  } else{#
    x <- ggplot(graph_data, aes(x=Stim, y=DV,group = Task, linetype = Task)) + #
      ylim(ylimit) +#
      ylab(ylab) +#
      geom_line(aes(group = Task, linetype = Task),position=position_dodge(width=.1),stat="identity") + #
      geom_linerange(aes(ymin=DV - SE, ymax=DV + SE), position=position_dodge(width=.1))+#
      theme(strip.background = element_rect(fill="#FFFFFF"), #
            strip.text = element_text(size=12), #
            axis.text = element_text(size=12),#
            axis.title = element_text(size=14),#
            title = element_text(size=16),#
            panel.grid = element_blank(),#
            axis.text.x=element_blank(),#
            axis.title.x=element_blank(),#
            legend.position= "none")}#
  #arrows(x, (c(comp.graph.mean) + c(comp.graph.se)+0.01), x, (c(comp.graph.mean) - c(comp.graph.se)-0.01), code = 0)#
  return(x)#
}#
<<<<<<< Updated upstream
mydata <- createdata()#
#
#calculate means#
submeans<-aggregate(mydata$fixtarg,by=list(mydata$subject,mydata$condition,mydata$bin),FUN=mean)#
colnames(submeans)<-c("subject","condition","bin","fixtarg")#
means<-aggregate(submeans$fixtarg,by=list(submeans$condition,submeans$bin),FUN=mean)#
colnames(means)<-c("condition","bin","fixtarg")#
temp<-aggregate(submeans$fixtarg,by=list(submeans$condition,submeans$bin),FUN=sd)#
means$se<-temp[,3]/(s_n^.5)
summary(mydata)
0.05/20
logit(1)
log((1/0))
log((0.95/0.05))
?names
load("/Users/hrabagli/Documents/Studies/Sense Resolution/3_Online_ET/ETAutismData/FullStats_April1.RDATA")
ls()
Full.Clusters
3*12
36+7
43/2
36+8
/2
44/22
?grepl
a = ("aa","bb","ss","ba")
a = c("aa","bb","ss","ba")
a
grep(a,"b")
grep("b",a)
grep("b",a) -1
a[(grep("b",a) -1)]
?rlnorm
runif(1,0,.5)
rlnorm(n(),1.5,.7)
library(ggplot2)#
library(gridExtra)#
library(grid)#
library(ez)#
library(lme4)#
library(doBy)#
=======
RT <- Comp_Graph_l(comp.rt$rt.mean,comp.rt$rtAdj.sd, comp.rt$Stim, comp.rt$DetailedTask, comp$Subj, paste("Two Words", "Reaction Time", sep = " "), c(700,1000),"Reaction Time (ms)",leg = TRUE)#
par(fig = c(0,1,0,0.35),mar = c(3,4,2,2), new = TRUE)#
Acc <- Comp_Graph_l(comp.Acc$Acc.mean,comp.Acc$AccAdj.sd, comp.Acc$Stim, comp.Acc$DetailedTask, comp$Subj, paste("Two Words", "Accuracy", sep = " "), c(0.7,1.03),"Accuracy")#
#
# Get the gtables#
gRT <- ggplotGrob(RT)#
gAcc <- ggplotGrob(Acc)#
#
# Set the widths#
gAcc$widths <- gRT$widths#
#
# Arrange the two charts.#
# The legend boxes are centered#
grid.newpage()#
grid.arrange(gAcc,gRT, nrow = 2, heights = c(1,2))
summary(comp)
comp.1a <- comp
library(reshape2)#
library(ggplot2)#
library(gridExtra)#
library(grid)#
library(jsonlite)#
library(ez)#
#
# This script is used to read in all the csv files in a folder.#
#
library(doBy)#
## for bootstrapping 95% confidence intervals -- from Mike Frank https://github.com/langcog/KTE/blob/master/mcf.useful.R#
library(bootstrap)#
theta <- function(x,xdata,na.rm=T) {mean(xdata[x],na.rm=na.rm)}#
ci.low <- function(x,na.rm=T) {#
  quantile(bootstrap(1:length(x),1000,theta,x,na.rm=na.rm)$thetastar,.025,na.rm=na.rm)} #  mean(x,na.rm=na.rm) -#
ci.high <- function(x,na.rm=T) {#
  quantile(bootstrap(1:length(x),1000,theta,x,na.rm=na.rm)$thetastar,.975,na.rm=na.rm) } #- mean(x,na.rm=na.rm)}#
#
Catch_Import= function(path_name){#
library(jsonlite)#
#
list.files(path = path_name,full.names = T, pattern = ".txt") -> file_list#
comp = c()#
for (x in file_list){#
	file_name = x#
	df <- fromJSON(file_name)#
	d <- df$data[4]$trialdata[1:2,]   ##df$data[4]$trialdata$key_press %in% c(71,32),]#
	d$Subj <- unique(df$data$trialdata[df$data$trialdata$Screen == "Real-Response",]$Subj)[2]#
	output <- cbind(key = d$key_press,Subj = d$Subj)#
	comp = rbind(comp,output)#
	print(x)#
	}#
	return(comp)#
}#
Comp_Import = function(path_name){#
library(jsonlite)#
#
list.files(path = path_name,full.names = T, pattern = ".txt") -> file_list#
comp = c()#
for (x in file_list){#
	file_name = x#
	df <- fromJSON(file_name)#
	d <- df$data$trialdata[df$data$trialdata$Screen == "Real-Response",]#
	d <- d[d$stims$Cond %in% c("Mismatch-Mask-List","Mismatch-Disjunc","Mismatch-Mask-Adj", "Mismatch-Color", "Mismatch-Noun" ,"Match-Mask-List","Match-List","Match-Mask-Adj", "Match-Adj", "Mismatch-Disjunc", "Match-Noun", "Match-Color"),]#
	#d <- d[d$stims$Cond %in% c("Match-Mask-List","Match-List","Match-Mask-Adj", "Match-Adj" ),]#
	d$Cond <- as.factor(d$stims$Cond)#
	d$Item <- as.factor(d$stims$Item)#
	d$Task <- "Disjunction"#
	#print(summary(d))#
	d[d$Cond %in% c("Match-Adj", "Match-Mask-Adj","Mismatch-Mask-Adj", "Mismatch-Color", "Mismatch-Noun" ),]$Task <- "Phrase"#
	d$Task <- as.factor(d$Task)#
	d$Stim <- "One Word"#
	d[d$Cond %in% c("Match-Adj", "Match-Noun","Match-Color","Mismatch-Disjunc","Mismatch-Color", "Mismatch-Noun"),]$Stim <- "Two Words"#
	d$Stim <- ordered(d$Stim, levels = c("One Word", "Two Words"))#
	d$Match <- "Match"#
	d[d$stims$Cond %in% c("Mismatch-Mask-List","Mismatch-Disjunc","Mismatch-Mask-Adj", "Mismatch-Color", "Mismatch-Noun","Mismatch-Disjunc"),]$Match <- "MisMatch"#
	d$Match <- as.factor(d$Match)#
	output <- data.frame(rt = as.numeric(as.character(d$rt)), key_press = d$key_press, Subj = d$Subj, Item = d$Item, Cond = d$Cond, Task = d$Task, Stim = d$Stim, Match = d$Match)#
	output$rt <- as.numeric(as.character(output$rt))#
	comp = rbind(comp,output)#
	print(x)#
	}#
	return(comp)#
}#
#
# Function for plotting data#
# Function for plotting data#
Comp_Graph = function(DV.mean, DV.se, IV1, IV2, Subj, title,ylimit,ylab,leg = FALSE){#
DV.se <- DV.se/(sqrt(length(unique(Subj))))#
comp.graph.mean <- tapply(DV.mean,list(IV1, IV2), mean)#
comp.graph.se <- tapply(DV.se,list(IV1, IV2), mean)#
if (leg == TRUE){#
x <- barplot(comp.graph.mean, beside = T, ylim = ylimit, ylab = ylab, legend = T, xpd = FALSE, names.arg = c("Composition Task\nPink Tree","List Task\nPink, Tree"),  col = c("gray47"), density = c(40,100), args.legend = list(bty = "n", x = 2.2), tck = -0.01)#
} else{#
x <- barplot(comp.graph.mean, beside = T, ylim = ylimit, ylab = ylab,  legend = F, xpd = FALSE, names.arg = c("Composition Task\nPink Tree","List Task\nPink, Tree"),   col = c("gray47"), density = c(40,100), tick = FALSE, axes = FALSE)#
axis(2, at = c(0.5,0.75,1), labels = c(0.5,0.75,1.0), tck = -0.03)#
}#
arrows(x, (c(comp.graph.mean) + c(comp.graph.se)+0.01), x, (c(comp.graph.mean) - c(comp.graph.se)-0.01), code = 0)#
}#
library(lme4)#
catch <- Catch_Import("./Exp1b")#
print(catch)#
comp <- Comp_Import("./Exp1b")#
contrasts(comp$Stim) <- c(-0.5,0.5)#
comp <- comp[comp$rt > 300 & comp$rt <1500,]#
comp$Acc <- 0#
comp[comp$key_press == 77 & comp$Match == "Match",]$Acc <- 1#
comp[comp$key_press == 90 & comp$Match == "MisMatch",]$Acc <- 1#
comp$Task <- factor(comp$Task, levels(comp$Task)[c(2,1)])#
contrasts(comp$Task) <- c(-0.5,0.5)#
# Prep for w-subj SEs#
comp$rtAdj <- NA#
comp$AccAdj <- NA#
for (i in unique(comp$Subj)){#
	comp[comp$Subj == i,]$rtAdj <- ((comp[comp$Subj == i,]$rt - mean(comp[comp$Subj == i,]$rt, na.rm = T)) + mean(comp$rt, na.rm = T))#
	comp[comp$Subj == i,]$AccAdj <- ((comp[comp$Subj == i,]$Acc - mean(comp[comp$Subj == i,]$Acc, na.rm = T)) + mean(comp$Acc, na.rm = T))#
	}#
comp$base_item <- as.factor(colsplit(comp$Item,"_",names = c("word1","word2"))[,2])#
contrasts(comp$Stim)[1] <- -1#
contrasts(comp$Task)[1] <- -1#
contrasts(comp$Stim)[2] <- 1#
contrasts(comp$Task)[2] <- 1#
#
# RT Analyses#
lmer(rt ~ Stim * Task + (1+Stim+Task|Subj)+ (1+Stim|base_item) , data = subset(comp, Acc ==1 & Match == "Match")) -> exp1b.full#
lmer(rt ~ Stim + Task + (1+Stim+Task|Subj)+ (1+Stim|base_item) , data = subset(comp, Acc ==1 & Match == "Match")) -> exp1b.noint#
anova(exp1b.full, exp1b.noint)#
#
lmer(rt ~ Stim  + (1+Stim|Subj)+ (1+Stim|base_item) , data = subset(comp, Acc ==1 & Match == "Match" & Task == "Phrase")) -> exp1b.full.phrase#
lmer(rt ~ 1 + (1+Stim|Subj)+ (1+Stim|base_item) , data = subset(comp, Acc ==1 & Match == "Match" & Task == "Phrase")) -> exp1b.noint.phrase#
anova(exp1b.full.phrase, exp1b.noint.phrase)#
#
lmer(rt ~ Stim  + (1+Stim|Subj)+ (1+Stim|base_item) , data = subset(comp, Acc ==1 & Match == "Match" & Task != "Phrase")) -> exp1b.full.nophrase#
lmer(rt ~ 1 + (1+Stim|Subj)+ (1+Stim|base_item) , data = subset(comp, Acc ==1 & Match == "Match" & Task != "Phrase")) -> exp1b.noint.nophrase#
anova(exp1b.full.nophrase, exp1b.noint.nophrase)#
#
ezANOVA(subset(comp, Acc ==1 & Match == "Match" ), rt, wid = .(Subj), within = .(Stim, Task))$ANOVA#
ezANOVA(subset(comp, Acc ==1 & Match == "Match" & Task == "Disjunction"), rt, wid = .(Subj), within = .(Stim))$ANOVA#
ezANOVA(subset(comp, Acc ==1 & Match == "Match" & Task != "Disjunction"), rt, wid = .(Subj), within = .(Stim))$ANOVA#
#
ezANOVA(comp, Acc, wid = .(Subj), within = .(Stim,Task))$ANOVA#
#
#GLMER analysis (Task removed for convergence)#
glmer(Acc ~ Task * Stim + (1+Stim|Subj) + (1+Stim|base_item), data = comp, family = "binomial") -> exp1b.acc.full#
glmer(Acc ~ Task + Stim + (1+Stim|Subj) + (1+Stim|base_item), data = comp, family = "binomial") -> exp1b.acc.noint#
anova(exp1b.acc.full, exp1b.acc.noint)#
#
# Stim removed for convergence#
glmer(Acc ~ Stim + (1|Subj) + (1|base_item), data = subset(comp, Task == "Phrase"), family = "binomial") -> exp1b.acc.full.phrase#
glmer(Acc ~  1 + (1|Subj) + (1|base_item), data = subset(comp, Task == "Phrase"), family = "binomial") -> exp1b.acc.noint.phrase#
anova(exp1b.acc.full.phrase, exp1b.acc.noint.phrase)#
#
glmer(Acc ~  Stim + (1|Subj) + (1|base_item), data = subset(comp, Task != "Phrase"), family = "binomial") -> exp1b.acc.full.nophrase#
glmer(Acc ~  1 + (1|Subj) + (1|base_item), data = subset(comp, Task != "Phrase"), family = "binomial") -> exp1b.acc.noint.nophrase#
anova(exp1b.acc.full.nophrase, exp1b.acc.noint.nophrase)#
# Prep data for bar graph#
comp$DetailedTask <- "List (Pink,Tree)"#
comp[comp$Task == "Phrase",]$DetailedTask <- "Phrase (Pink Tree)"#
comp$DetailedTask <- ordered(comp$DetailedTask, levels = c("Phrase (Pink Tree)", "List (Pink,Tree)"))#
comp$Stim <- ordered(comp$Stim, levels = c("Two Words", "One Word"))#
comp.rt <- summaryBy(rt + rtAdj ~ Task +DetailedTask + Stim  + Subj, , data = subset(comp, Acc ==1 & Match == "Match"), FUN = c(mean), na.rm = T , keep.names = T)#
comp.rt <- summaryBy(rt + rtAdj ~ Task +DetailedTask+ Stim  , , data = comp.rt, FUN = c(mean,sd), na.rm = T )#
print(comp.rt)#
#
comp.Acc <- summaryBy(Acc + AccAdj~  Task +DetailedTask + Stim  +Subj, , data = comp, FUN = c(mean), na.rm = T , keep.names = T)#
comp.Acc <- summaryBy(Acc + AccAdj~  Task +DetailedTask + Stim  , , data = comp, FUN = c(mean,sd), na.rm = T )#
print(comp.Acc)#
#
par(fig = c(0,1,0.35,1),mar = c(3,4,2,2))#
Comp_Graph(comp.rt$rt.mean,comp.rt$rtAdj.sd, comp.rt$Stim, comp.rt$DetailedTask, comp$Subj, paste("Two Words", "Reaction Time", sep = " "), c(650,900),"Reaction Time (ms)",leg = TRUE)#
par(fig = c(0,1,0,0.35),mar = c(3,4,2,2), new = TRUE)#
Comp_Graph(comp.Acc$Acc.mean,comp.Acc$AccAdj.sd, comp.Acc$Stim, comp.Acc$DetailedTask, comp$Subj, paste("Two Words", "Accuracy", sep = " "), c(0.5,1),"Accuracy")#
# Prep data for line graph#
comp$DetailedTask <- ordered(comp$DetailedTask, levels = c("Phrase (Pink Tree)", "List (Pink,Tree)"))#
comp$Stim <- ordered(comp$Stim, levels = c("One Word", "Two Words"))#
#
comp.rt <- summaryBy(rt + rtAdj ~ Task +DetailedTask + Stim  + Subj, , data = subset(comp, Acc ==1 & Match == "Match"), FUN = c(mean), na.rm = T , keep.names = T)#
# Print means and cis#
ci.m <- aggregate(rt ~  Stim + DetailedTask , comp.rt, mean); ci.m#
ci.l <- aggregate(rt ~  Stim + DetailedTask , comp.rt, ci.low); ci.l#
ci.h <- aggregate(rt ~  Stim + DetailedTask , comp.rt, ci.high); ci.h#
comp.rt <- summaryBy(rt + rtAdj ~ Task +DetailedTask+ Stim  , , data = comp.rt, FUN = c(mean,sd), na.rm = T )#
comp.Acc <- summaryBy(Acc + AccAdj~  Task +DetailedTask + Stim  +Subj, , data = comp, FUN = c(mean), na.rm = T , keep.names = T)#
comp.Acc <- summaryBy(Acc + AccAdj~  Task +DetailedTask + Stim  , , data = comp, FUN = c(mean,sd), na.rm = T )#
#
# Function for plotting data in line graph#
Comp_Graph_l = function(DV.mean, DV.se, IV1, IV2, Subj, title,ylimit,ylab,leg = FALSE){#
theme_set(theme_bw())#
DV.se <- DV.se/(sqrt(length(unique(Subj))))#
#
graph_data <- data.frame(Stim = IV1, Task = IV2, DV = DV.mean, SE = DV.se)#
print((graph_data))#
if (leg == TRUE){#
# PRetty ggplot2 code drawn from https://github.com/langcog/KTE/blob/master/full%20analysis%20all%20experiments.R#
x <- ggplot(graph_data, aes(x=Stim, y=DV,group = Task, linetype = Task)) + #
		ylim(ylimit) +#
		ylab(ylab) +#
		geom_line(aes(group = Task, linetype = Task),position=position_dodge(width=.1),stat="identity") + #
		geom_linerange(aes(ymin=DV - SE, ymax=DV + SE), position=position_dodge(width=.1))+ #
#
		guides(colour=guide_legend()) +#
		theme(strip.background = element_rect(fill="#FFFFFF"), #
        strip.text = element_text(size=12), #
        axis.text = element_text(size=12),#
        axis.title = element_text(size=14),#
        legend.text = element_text(size=12),#
        legend.key = element_blank(),#
       legend.title=element_blank(),#
        title = element_text(size=16),#
        panel.grid = element_blank(),#
         axis.title.x=element_blank(),#
        legend.position=c(0.3,0.8))#
} else{#
x <- ggplot(graph_data, aes(x=Stim, y=DV,group = Task, linetype = Task)) + #
		ylim(ylimit) +#
		ylab(ylab) +#
		geom_line(aes(group = Task, linetype = Task),position=position_dodge(width=.1),stat="identity") + #
		geom_linerange(aes(ymin=DV - SE, ymax=DV + SE), position=position_dodge(width=.1))+#
		theme(strip.background = element_rect(fill="#FFFFFF"), #
        strip.text = element_text(size=12), #
        axis.text = element_text(size=12),#
        axis.title = element_text(size=14),#
        title = element_text(size=16),#
        panel.grid = element_blank(),#
        axis.text.x=element_blank(),#
       axis.title.x=element_blank(),#
  	   	legend.position= "none")}#
return(x)#
}#
RT <- Comp_Graph_l(comp.rt$rt.mean,comp.rt$rtAdj.sd, comp.rt$Stim, comp.rt$DetailedTask, comp$Subj, paste("Two Words", "Reaction Time", sep = " "), c(650,1000),"Reaction Time (ms)",leg = TRUE)#
par(fig = c(0,1,0,0.35),mar = c(3,4,2,2), new = TRUE)#
Acc <- Comp_Graph_l(comp.Acc$Acc.mean,comp.Acc$AccAdj.sd, comp.Acc$Stim, comp.Acc$DetailedTask, comp$Subj, paste("Two Words", "Accuracy", sep = " "), c(0.7,1.03),"Accuracy")#
#
# Get the gtables#
gRT <- ggplotGrob(RT)#
gAcc <- ggplotGrob(Acc)#
#
# Set the widths#
gAcc$widths <- gRT$widths#
#
# Arrange the two charts.#
# The legend boxes are centered#
grid.newpage()#
grid.arrange(gAcc,gRT, nrow = 2, heights = c(1,2))
summary(comp)
comp.1b <- comp
summary(comp.1a)
comp.comb <- rbind(comp.1a, comp.1b)
summary(comp.comb)
comp.1a$Expt <- "1a"
comp.1b$Expt <- "1b"
comp.comb <- rbind(comp.1a, comp.1b)
lmer(rt ~ Expt + (1|Subj) + (1|base_item), data = comp.comb)
summary(lmer(rt ~ Expt + (1|Subj) + (1|base_item), data = comp.comb))
summary(lmer(rt ~ Expt*Task*Stim + (1|Subj) + (1|base_item), data = comp.comb))
>>>>>>> Stashed changes
library(reshape2)#
library(ggplot2)#
library(gridExtra)#
library(grid)#
library(jsonlite)#
library(ez)#
<<<<<<< Updated upstream
=======
# This script is used to read in all the csv files in a folder.#
>>>>>>> Stashed changes
#
library(doBy)#
## for bootstrapping 95% confidence intervals -- from Mike Frank https://github.com/langcog/KTE/blob/master/mcf.useful.R#
library(bootstrap)#
theta <- function(x,xdata,na.rm=T) {mean(xdata[x],na.rm=na.rm)}#
ci.low <- function(x,na.rm=T) {#
  quantile(bootstrap(1:length(x),1000,theta,x,na.rm=na.rm)$thetastar,.025,na.rm=na.rm)} #  mean(x,na.rm=na.rm) -#
ci.high <- function(x,na.rm=T) {#
  quantile(bootstrap(1:length(x),1000,theta,x,na.rm=na.rm)$thetastar,.975,na.rm=na.rm) } #- mean(x,na.rm=na.rm)}#
Catch_Import= function(path_name){#
library(jsonlite)#
#
list.files(path = path_name,full.names = T, pattern = ".txt") -> file_list#
comp = c()#
for (x in file_list){#
	file_name = x#
	df <- fromJSON(file_name)#
	d <- df$data$trialdata[1:2,]   ##df$data$trialdata$key_press %in% c(71,32),]#
	d$Subj <- unique(df$data$trialdata[df$data$trialdata$Screen == "Real-Response",]$Subj)[2]#
	output <- cbind(key = d$key_press,Subj = d$Subj)#
	comp = rbind(comp,output)#
	print(x)#
	}#
	return(comp)#
}#
Comp_Import = function(path_name){#
library(jsonlite)#
#
list.files(path = path_name,full.names = T, pattern = ".txt") -> file_list#
comp = c()#
for (x in file_list){#
	file_name = x#
	df <- fromJSON(file_name)#
	d <- df$data$trialdata[df$data$trialdata$Screen == "Real-Response",]#
	d <- d[ grep("match",d$stims$Cond, ignore.case = TRUE),]#
	#d <- d[d$stims$Cond %in% c("Mismatch-Mask-List","Mismatch-List","Mismatch-Mask-Adj", "Mismatch-Color", "Mismatch-Noun" ,"Match-Mask-List","Match-List","Match-Mask-Adj", "Match-Adj", "Mismatch-Disjunc", "Match-Noun", "Match-Color"),]#
	#d <- d[d$stims$Cond %in% c("Match-Mask-List","Match-List","Match-Mask-Adj", "Match-Adj" ),]#
	d$Cond <- as.factor(d$stims$Cond)#
	d$Type <- as.factor(d$stims$Type)#
	d$Phrase <- as.factor(d$stims$Phrase)#
	d$Length <- as.factor(d$stims$Length)#
	d$Task <- "Phrase"#
	d$Task <- as.factor(d$Task)#
	d$Stim <- "Two Words"#
	d[d$Length == "1",]$Stim <- "One Word"#
	d$Stim <- ordered(d$Stim, levels = c("Two Words", "One Word"))#
	d$PicType <- ifelse(d$Type == "Color", "Variable Colors (as Experiment 1)","Fixed Colors")#
	d$PicType <- ordered(d$PicType, levels = c("Variable Colors (as Experiment 1)", "Fixed Colors"))#
	d$Match <- "Match"#
	d[grep("mismatch",d$Cond, ignore.case = TRUE),]$Match <- "MisMatch"#
	d$Block <- rep(c(1,2), each = 100)#
	d$Match <- as.factor(d$Match)#
	output <- data.frame(rt = as.numeric(as.character(d$rt)), key_press = d$key_press, Subj = d$Subj, Cond = d$Cond, Type = d$Type, Task = d$Task, Stim = d$Stim, Pic = d$stims$Pic, Phrase = d$Phrase, Match = d$Match, PicType = d$PicType, Length = d$Length, Block = d$Block)#
	#print(summary(d))#
	output$rt <- as.numeric(as.character(output$rt))#
	comp = rbind(comp,output)#
	print(x)#
	}#
	return(comp)#
}#
#
# Function for plotting data#
Comp_Graph = function(DV.mean, DV.se, IV1, IV2, Subj, title,ylimit,ylab,leg = FALSE){#
DV.se <- DV.se/(sqrt( (length(unique(Subj))/2) ))#
comp.graph.mean <- tapply(DV.mean,list(IV1, IV2), mean)#
comp.graph.se <- tapply(DV.se,list(IV1, IV2), mean)#
if (leg == TRUE){#
x <- barplot(comp.graph.mean, beside = T, ylim = ylimit, ylab = ylab, legend = T, xpd = FALSE, names.arg = c("Mismatched Predictability\nPink Tree","Matched Predictability\nPink Tree"),  col = c("gray47"), density = c(40,100), args.legend = list(bty = "n", x = 5), tck = -0.01)#
} else{#
x <- barplot(comp.graph.mean, beside = T, ylim = ylimit, ylab = ylab,  legend = F, xpd = FALSE, names.arg = c("Mismatched Predictability\nPink Tree","Matched Predictability\nPink Tree"),   col = c("gray47"), density = c(40,100), tick = FALSE, axes = FALSE)#
axis(2, at = c(0.5,0.75,1), labels = c(0.5,0.75,1.0), tck = -0.03)#
}#
arrows(x, (c(comp.graph.mean) + c(comp.graph.se)+0.01), x, (c(comp.graph.mean) - c(comp.graph.se)-0.01), code = 0)#
}#
library(lme4)#
library(ez)#
catch <- Catch_Import("./Exp1c")#
print(catch)#
comp <- Comp_Import("./Exp1c")#
comp$Acc <- 0#
comp[comp$key_press == 77 & comp$Match == "Match",]$Acc <- 1#
comp[comp$key_press == 90 & comp$Match == "MisMatch",]$Acc <- 1#
comp$Task <- factor(comp$Task, levels(comp$Task)[c(2,1)])#
comp <- comp[comp$rt > 300 & comp$rt <1500,]#
comp$rtAdj <- NA#
comp$AccAdj <- NA#
for (i in unique(comp$Subj)){#
	comp[comp$Subj == i,]$rtAdj <- ((comp[comp$Subj == i,]$rt - mean(comp[comp$Subj == i,]$rt, na.rm = T)) + mean(comp$rt, na.rm = T))#
	comp[comp$Subj == i,]$AccAdj <- ((comp[comp$Subj == i,]$Acc - mean(comp[comp$Subj == i,]$Acc, na.rm = T)) + mean(comp$Acc, na.rm = T))#
	}#
<<<<<<< Updated upstream
comp.omni$PicType <- as.factor(comp.omni$PicType)#
#
comp.omni$Type <- as.factor(comp.omni$Type)#
summary(comp.omni)#
#
comp.omni$base_item <- as.factor(colsplit(comp.omni$Item,"_",names = c("word1","word2","word3"))[,3])#
#
contrasts( comp.omni$Type) <-contrasts(C(comp.omni$Type, "contr.sum"))#
contrasts( comp.omni$Stim) <-contrasts(C(comp.omni$Stim, "contr.sum"))#
#Reaction Times#
comp.omni$Num.Stim <- 0#
comp.omni[comp.omni$Stim == "One Word",]$Num.Stim <- -1#
comp.omni[comp.omni$Stim == "Three Words",]$Num.Stim <- 1#
#
lmer(rt ~ Num.Stim * Type  + (1+Num.Stim|Subj) + (1+Num.Stim+Type|base_item), data = subset(comp.omni, Acc ==1 & Match == "Match" & Task == "Phrase")) -> omni.full#
lmer(rt ~ Num.Stim + Type  + (1+Num.Stim|Subj) + (1+Num.Stim+Type|base_item), data = subset(comp.omni, Acc ==1 & Match == "Match" & Task == "Phrase")) -> omni.noint#
anova(omni.full,omni.noint)#
#
# Effect for 2 and 3 word phrases#
lmer(rt ~ Num.Stim * Type  + (1+Num.Stim|Subj) + (1+Num.Stim+Type|base_item), data = subset(comp.omni, Acc ==1 & Match == "Match" & Task == "Phrase" & Stim != "One Word")) -> omni.two_three#
lmer(rt ~ Num.Stim + Type  + (1+Num.Stim|Subj) + (1+Num.Stim+Type|base_item), data = subset(comp.omni, Acc ==1 & Match == "Match" & Task == "Phrase" & Stim != "One Word")) -> omni.two_three_sub#
anova(omni.two_three,omni.two_three_sub)#
#
# Effect for 1 and 2 word phrases#
lmer(rt ~ Num.Stim * Type  + (1+Num.Stim|Subj) + (1+Num.Stim+Type|base_item), data = subset(comp.omni, Acc ==1 & Match == "Match" & Task == "Phrase" & Stim != "Three Words")) -> omni.one_two#
lmer(rt ~ Num.Stim + Type  + (1+Num.Stim|Subj) + (1+Num.Stim+Type|base_item), data = subset(comp.omni, Acc ==1 & Match == "Match" & Task == "Phrase"& Stim != "Three Words")) -> omni.one_two_sub#
anova(omni.one_two,omni.one_two_sub)#
#
# Number of word effects for 2 and 3 word phrases for each condition#
lmer(rt ~ Num.Stim   + (1+Num.Stim|Subj) + (1+Num.Stim|base_item), data = subset(comp.omni, Acc ==1 & Match == "Match" & Task == "Phrase" & Type %in% c("Big") & Stim != "One Word")) -> exp2.full.two_three.big#
lmer(rt ~ 1  + (1+Num.Stim|Subj) + (1+Num.Stim|base_item), data = subset(comp.omni, Acc ==1 & Match == "Match" & Task == "Phrase" & Type %in% c("Big")& Stim != "One Word")) -> exp2.noint.two_three.big#
anova(exp2.full.two_three.big,exp2.noint.two_three.big)#
#
lmer(rt ~ Num.Stim   + (1+Num.Stim|Subj) + (1+Num.Stim|base_item), data = subset(comp.omni, Acc ==1 & Match == "Match" & Task == "Phrase" & Type %in% c("Dark") & Stim != "One Word")) -> exp2.full.two_three.dark#
lmer(rt ~ 1  + (1+Num.Stim|Subj) + (1+Num.Stim|base_item), data = subset(comp.omni, Acc ==1 & Match == "Match" & Task == "Phrase" & Type %in% c("Dark")& Stim != "One Word")) -> exp2.noint.two_three.dark#
anova(exp2.full.two_three.dark,exp2.noint.two_three.dark)#
#
# Number of word effects for 1 and 2 word phrases#
lmer(rt ~ Num.Stim   + (1+Num.Stim|Subj) + (1+Num.Stim|base_item), data = subset(comp.omni, Acc ==1 & Match == "Match" & Task == "Phrase"  & Stim != "Three Words")) -> exp2.full.one_two.length#
lmer(rt ~ 1  + (1+Num.Stim|Subj) + (1+Num.Stim|base_item), data = subset(comp.omni, Acc ==1 & Match == "Match" & Task == "Phrase" & Stim != "Three Words")) -> exp2.noint.one_two.length#
anova(exp2.full.one_two.length,exp2.noint.one_two.length)#
#
# Type Effects - remove by subject for convergence#
lmer(rt ~ Type   + (1|Subj) + (1+Type|base_item), data = subset(comp.omni, Acc ==1 & Match == "Match" & Task == "Phrase"  & Stim != "Three Words")) -> exp2.full.one_two.type#
lmer(rt ~ 1  + (1|Subj) + (1+Type|base_item), data = subset(comp.omni, Acc ==1 & Match == "Match" & Task == "Phrase" & Stim != "Three Words")) -> exp2.noint.one_two.type#
anova(exp2.full.one_two.type,exp2.noint.one_two.type)#
ezANOVA(subset(comp.omni, Acc ==1 & Match == "Match" & Task == "Phrase"), rt, wid = .(Subj), within = .(Stim), between = .(Type))$ANOVA#
ezANOVA(subset(comp.omni, Acc ==1 & Match == "Match" & Task == "Phrase" & Stim != "Three Words"), rt, wid = .(Subj), within = .(Stim), between = .(Type))$ANOVA#
#
ezANOVA(subset(comp.omni, Acc ==1 & Match == "Match" & Task == "Phrase" & Type == "Big"), rt, wid = .(Subj), within = .(Stim))$ANOVA#
ezANOVA(subset(comp.omni, Acc ==1 & Match == "Match" & Task == "Phrase" & Type == "Dark"), rt, wid = .(Subj), within = .(Stim))$ANOVA#
#
ezANOVA(subset(comp.omni, Acc ==1 & Match == "Match" & Task == "Phrase" & Type == "Big" & Stim != "One Word"), rt, wid = .(Subj), within = .(Stim))$ANOVA#
ezANOVA(subset(comp.omni, Acc ==1 & Match == "Match" & Task == "Phrase" & Type == "Dark" & Stim != "One Word"), rt, wid = .(Subj), within = .(Stim))$ANOVA#
ezANOVA(subset(comp.omni, Acc ==1 & Match == "Match" & Task == "Phrase" & Type == "Big" & Stim != "Three Words"), rt, wid = .(Subj), within = .(Stim))$ANOVA#
ezANOVA(subset(comp.omni, Acc ==1 & Match == "Match" & Task == "Phrase" & Type == "Dark" & Stim != "Three Words"), rt, wid = .(Subj), within = .(Stim))$ANOVA#
# Accuracy#
ezANOVA(comp.omni, Acc, wid = .(Subj), within = .(Stim), between = .(Type))$ANOVA#
#
# GLMER Analysis (Type between subject). Convert Stim into numeric so we don't have to deal with 3-level factor.#
comp.omni$Num.Stim <- 0#
comp.omni[comp.omni$Stim == "One Word",]$Num.Stim <- -1#
comp.omni[comp.omni$Stim == "Three Words",]$Num.Stim <- 1#
exp2.acc.full <- glmer(Acc ~ Type * Num.Stim + (1+Num.Stim+Type|Subj) + (1|base_item) , data = comp.omni, family = "binomial")#
exp2.acc.noint <- glmer(Acc ~ Type + Num.Stim + (1+Num.Stim+Type|Subj) + (1|base_item), data = comp.omni, family = "binomial")#
anova(exp2.acc.full,exp2.acc.noint)#
#
# Length effect#
exp2.acc.full.length <- glmer(Acc ~  Num.Stim + (1+Num.Stim|Subj) , data = comp.omni, family = "binomial")#
exp2.acc.noint.length <- glmer(Acc ~ 1 + (1+Num.Stim|Subj) , data = comp.omni, family = "binomial")#
anova(exp2.acc.full.length,exp2.acc.noint.length)#
#
comp.omni$rtAdj <- NA#
comp.omni$AccAdj <- NA#
for (i in unique(comp.omni$Subj)){#
	comp.omni[comp.omni$Subj == i,]$rtAdj <- ((comp.omni[comp.omni$Subj == i,]$rt - mean(comp.omni[comp.omni$Subj == i,]$rt, na.rm = T)) + mean(comp.omni$rt, na.rm = T))#
	comp.omni[comp.omni$Subj == i,]$AccAdj <- ((comp.omni[comp.omni$Subj == i,]$Acc - mean(comp.omni[comp.omni$Subj == i,]$Acc, na.rm = T)) + mean(comp.omni$Acc, na.rm = T))#
	}#
#
# Prep for bar graph#
comp.omni$DetailedType <- "Complex (Dark Pink Tree)"#
comp.omni[comp.omni$Type == "Big",]$DetailedType <- "Simple (Big Pink Tree)"#
comp.omni$DetailedType <- ordered(comp.omni$DetailedType, levels = c("Simple (Big Pink Tree)", "Complex (Dark Pink Tree)"))#
comp.omni$Stim <- ordered(comp.omni$Stim, levels = c( "One Word","Two Words","Three Words"))#
#
comp.omni.rt <- summaryBy(rt + rtAdj ~ Type+ DetailedType + Stim + Subj, , data = subset(comp.omni, Acc ==1 & Match == "Match"), FUN = c(mean), na.rm = T , keep.names = T)#
comp.omni.rt <- summaryBy(rt + rtAdj ~ Type+ DetailedType + Stim , , data = comp.omni.rt, FUN = c(mean,sd), na.rm = T )#
print(comp.omni.rt)#
#
comp.omni.Acc <- summaryBy(Acc + AccAdj~  Type + DetailedType+ Stim  +Subj, , data = comp.omni, FUN = c(mean), na.rm = T , keep.names = T)#
comp.omni.Acc <- summaryBy(Acc + AccAdj~  Type + DetailedType+ Stim  , , data = comp.omni.Acc, FUN = c(mean,sd), na.rm = T )#
print(comp.omni.Acc)#
#
par(fig = c(0,1,0.35,1),mar = c(3,4,2,2))#
Comp_Graph(comp.omni.rt$rt.mean,comp.omni.rt$rtAdj.sd, comp.omni.rt$Stim, comp.omni.rt$Type, comp.omni$Subj, paste("Three Words", "Reaction Time", sep = " "), c(650,900),"Reaction Time (ms)",leg = TRUE)#
par(fig = c(0,1,0,0.35),mar = c(3,4,2,2), new = TRUE)#
Comp_Graph(comp.omni.Acc$Acc.mean,comp.omni.Acc$AccAdj.sd, comp.omni.Acc$Stim, comp.omni.Acc$Type, comp.omni$Subj, paste("Three Words", "Accuracy", sep = " "), c(0.5,1),"Accuracy")#
# Prep for line graph#
comp.omni$Stim <- ordered(comp.omni$Stim,  levels = c("One Word", "Two Words", "Three Words"))#
comp.omni$DetailedType <- ordered(comp.omni$DetailedType, levels = c("Complex (Dark Pink Tree)","Simple (Big Pink Tree)"))#
comp.omni.rt <- summaryBy(rt + rtAdj ~ Type+ DetailedType + Stim + Subj, , data = subset(comp.omni, Acc ==1 & Match == "Match"), FUN = c(mean), na.rm = T , keep.names = T)#
ci.m <- aggregate(rt ~  Stim + DetailedType , comp.omni.rt, mean); ci.m#
ci.l <- aggregate(rt ~  Stim + DetailedType , comp.omni.rt, ci.low); ci.l#
ci.h <- aggregate(rt ~  Stim + DetailedType , comp.omni.rt, ci.high); ci.h#
#
comp.omni.rt <- summaryBy(rt + rtAdj ~ Type+ DetailedType + Stim , , data = comp.omni.rt, FUN = c(mean,sd), na.rm = T )#
#
comp.omni.Acc <- summaryBy(Acc + AccAdj~  Type + DetailedType+ Stim  +Subj, , data = comp.omni, FUN = c(mean), na.rm = T , keep.names = T)#
comp.omni.Acc <- summaryBy(Acc + AccAdj~  Type + DetailedType+ Stim  , , data = comp.omni.Acc, FUN = c(mean,sd), na.rm = T )#
=======
comp$base_item <- as.factor(colsplit(comp$Pic,"_",names = c("prop1","prop2","prop3","prop4"))[,1])#
contrasts(comp$Stim)[1] <- -1#
contrasts(comp$Type)[1] <- -1#
contrasts(comp$Stim)[2] <- 1#
contrasts(comp$Type)[2] <- 1#
#
# RT Analyses#
lmer(rt ~ Stim * Type + (1+Stim|Subj)+ (1+Stim*Type|base_item) , data = subset(comp, Acc ==1 & Match == "Match")) -> exp1c.full#
lmer(rt ~ Stim + Type + (1+Stim|Subj)+ (1+Stim*Type|base_item) , data = subset(comp, Acc ==1 & Match == "Match")) -> exp1c.noint#
anova(exp1c.full, exp1c.noint)#
#
lmer(rt ~ Stim  + (1+Stim|Subj)+ (1+Stim|base_item) , data = subset(comp, Acc ==1 & Match == "Match" & Type == "Color")) -> exp1c.full.color#
lmer(rt ~ 1 + (1+Stim|Subj)+ (1+Stim|base_item) , data = subset(comp, Acc ==1 & Match == "Match" & Type == "Color")) -> exp1c.noint.color#
anova(exp1c.full.color, exp1c.noint.color)#
#
lmer(rt ~ Stim  + (1+Stim|Subj)+ (1+Stim|base_item) , data = subset(comp, Acc ==1 & Match == "Match" & Type != "Color")) -> exp1c.full.nocolor#
lmer(rt ~ 1 + (1+Stim|Subj)+ (1+Stim|base_item) , data = subset(comp, Acc ==1 & Match == "Match" & Type != "Color")) -> exp1c.noint.nocolor#
anova(exp1c.full.nocolor, exp1c.noint.nocolor)#
ezANOVA(subset(comp, Acc ==1 & Match == "Match"), rt, wid = .(Subj), within = .(Stim), between = .(Type))$ANOVA#
ezANOVA(subset(comp, Acc ==1 & Match == "Match" & Type == "Color"), rt, wid = .(Subj), within = .(Stim))$ANOVA#
ezANOVA(subset(comp, Acc ==1 & Match == "Match" & Type == "FixedColor"), rt, wid = .(Subj), within = .(Stim))$ANOVA#
#
ezANOVA(comp, Acc, wid = .(Subj), within = .(Stim), between = .(Type))$ANOVA#
#
# LMER Analyis (Type between Subj, Stim within)#
glmer(Acc ~ Type * Stim + (1+Stim|Subj) + (1+Type|base_item), data = comp, family = "binomial") -> exp1c.acc.full#
glmer(Acc ~ Type + Stim + (1+Stim|Subj) + (1+Type|base_item), data = comp, family = "binomial") -> exp1c.acc.noint#
anova(exp1c.acc.full, exp1c.acc.noint)#
#
# Prep for bar graph#
comp$DetailedTask <- "Matched Predictability (Pink Tree)"#
comp[comp$Type == "Color",]$DetailedTask <- "Mismatched Predictability (Pink Tree)"#
comp$DetailedTask <- ordered(comp$DetailedTask, levels = c("Mismatched Predictability (Pink Tree)","Matched Predictability (Pink Tree)"))#
#
comp.rt <- summaryBy(rt + rtAdj ~ PicType + DetailedTask + Stim + Subj, , data = subset(comp, Acc ==1 & Match == "Match"), FUN = c(mean), na.rm = T , keep.names = T)#
comp.rt <- summaryBy(rt + rtAdj ~ PicType + DetailedTask + Stim , data = comp.rt, FUN = c(mean,sd), na.rm = T )#
print(comp.rt)#
comp.Acc <- summaryBy(Acc + AccAdj~  PicType + DetailedTask + Stim  +Subj, , data = comp, FUN = c(mean), na.rm = T , keep.names = T)#
comp.Acc <- summaryBy(Acc + AccAdj~  PicType + DetailedTask + Stim   , data = comp.Acc, FUN = c(mean,sd), na.rm = T )#
print(comp.Acc)#
#
par(fig = c(0,1,0.35,1),mar = c(3,4,2,2))#
Comp_Graph(comp.rt$rt.mean,comp.rt$rtAdj.sd, comp.rt$Stim, comp.rt$DetailedTask, comp$Subj, paste("Two Words", "Reaction Time", sep = " "), c(650,900),"Reaction Time (ms)",leg = TRUE)#
par(fig = c(0,1,0,0.35),mar = c(3,4,2,2), new = TRUE)#
Comp_Graph(comp.Acc$Acc.mean,comp.Acc$AccAdj.sd, comp.Acc$Stim, comp.Acc$DetailedTask, comp$Subj, paste("Two Words", "Accuracy", sep = " "), c(0.5,1),"Accuracy")#
#
# Prep for line graph#
comp$DetailedTask <- ordered(comp$DetailedTask, levels = c("Matched Predictability (Pink Tree)","Mismatched Predictability (Pink Tree)"))#
comp$Stim <- ordered(comp$Stim, levels = c("One Word", "Two Words"))#
#
comp.rt <- summaryBy(rt + rtAdj ~ PicType + DetailedTask + Stim + Subj, , data = subset(comp, Acc ==1 & Match == "Match"), FUN = c(mean), na.rm = T , keep.names = T)#
#
# Show subject means#
ggplot(comp.rt,aes(x = Stim, y = rt, color = Subj, group = Subj)) + facet_wrap(~DetailedTask)+#
  geom_path()+guides(color = FALSE, group = FALSE)+ ylab("Reaction Time (ms)")+xlab("Stimulus Length")#
ci.m <- aggregate(rt ~  Stim + DetailedTask , comp.rt, mean); ci.m#
ci.l <- aggregate(rt ~  Stim + DetailedTask , comp.rt, ci.low); ci.l#
ci.h <- aggregate(rt ~  Stim + DetailedTask , comp.rt, ci.high); ci.h#
comp.rt <- summaryBy(rt + rtAdj ~ PicType + DetailedTask + Stim , data = comp.rt, FUN = c(mean,sd), na.rm = T )#
comp.Acc <- summaryBy(Acc + AccAdj~  PicType + DetailedTask + Stim  +Subj, , data = comp, FUN = c(mean), na.rm = T , keep.names = T)#
comp.Acc <- summaryBy(Acc + AccAdj~  PicType + DetailedTask + Stim   , data = comp.Acc, FUN = c(mean,sd), na.rm = T )#
>>>>>>> Stashed changes
#
# Function for plotting data#
Comp_Graph_l = function(DV.mean, DV.se, IV1, IV2, Subj, title,ylimit,ylab,leg = FALSE){#
theme_set(theme_bw())#
<<<<<<< Updated upstream
DV.se <- DV.se/(sqrt((length(unique(Subj))/2)))#
graph_data <- data.frame(Stim = IV1, Task = IV2, DV = DV.mean, SE = DV.se)#
print((graph_data))#
if (leg == TRUE){#
=======
S <- length(unique(Subj))/2#
DV.se <- DV.se/(sqrt(S))#
#comp.graph.mean <- tapply(DV.mean,list(IV1, IV2), mean)#
#comp.graph.se <- tapply(DV.se,list(IV1, IV2), mean)#
graph_data <- data.frame(Stim = IV1, Task = IV2, DV = DV.mean, SE = DV.se)#
print((S))#
if (leg == TRUE){#
#x <- barplot(comp.graph.mean, beside = T, ylim = ylimit, ylab = ylab, legend = T, xpd = FALSE, names.arg = c("Composition Task\nPink Tree","List Task\nCup, Tree"),  col = c("gray47"), density = c(40,100), args.legend = list(bty = "n", x = 2.8), tck = -0.01)#
>>>>>>> Stashed changes
# PRetty ggplot2 code drawn from https://github.com/langcog/KTE/blob/master/full%20analysis%20all%20experiments.R#
#
#		#
x <- ggplot(graph_data, aes(x=Stim, y=DV,group = Task, linetype = Task)) + #
		ylim(ylimit) +#
		ylab(ylab) +#
		geom_line(aes(group = Task, linetype = Task),position=position_dodge(width=.1),stat="identity") + #
		geom_linerange(aes(ymin=DV - SE, ymax=DV + SE), position=position_dodge(width=.1))+ #
#
		guides(colour=guide_legend()) +#
		theme(strip.background = element_rect(fill="#FFFFFF"), #
        strip.text = element_text(size=12), #
        axis.text = element_text(size=12),#
        axis.title = element_text(size=14),#
        legend.text = element_text(size=12),#
        legend.key = element_blank(),#
       legend.title=element_blank(),#
        title = element_text(size=16),#
        panel.grid = element_blank(),#
         axis.title.x=element_blank(),#
<<<<<<< Updated upstream
        legend.position=c(0.2,0.8))#
=======
        legend.position=c(0.43,0.8))#
>>>>>>> Stashed changes
} else{#
x <- ggplot(graph_data, aes(x=Stim, y=DV,group = Task, linetype = Task)) + #
		ylim(ylimit) +#
		ylab(ylab) +#
		geom_line(aes(group = Task, linetype = Task),position=position_dodge(width=.1),stat="identity") + #
		geom_linerange(aes(ymin=DV - SE, ymax=DV + SE), position=position_dodge(width=.1))+#
		theme(strip.background = element_rect(fill="#FFFFFF"), #
        strip.text = element_text(size=12), #
        axis.text = element_text(size=12),#
        axis.title = element_text(size=14),#
        title = element_text(size=16),#
        panel.grid = element_blank(),#
        axis.text.x=element_blank(),#
       axis.title.x=element_blank(),#
  	   	legend.position= "none")}#
<<<<<<< Updated upstream
return(x)#
}#
RT <- Comp_Graph_l(comp.omni.rt$rt.mean,comp.omni.rt$rtAdj.sd, comp.omni.rt$Stim, comp.omni.rt$DetailedType, comp.omni$Subj, paste("Three Words", "Reaction Time", sep = " "), c(650,800),"Reaction Time (ms)",leg = TRUE)#
par(fig = c(0,1,0,0.35),mar = c(3,4,2,2), new = TRUE)#
Acc <- Comp_Graph_l(comp.omni.Acc$Acc.mean,comp.omni.Acc$AccAdj.sd, comp.omni.Acc$Stim, comp.omni.Acc$DetailedType, comp.omni$Subj, paste("Three Words", "Accuracy", sep = " "), c(0.7,1),"Accuracy")#
=======
#arrows(x, (c(comp.graph.mean) + c(comp.graph.se)+0.01), x, (c(comp.graph.mean) - c(comp.graph.se)-0.01), code = 0)#
return(x)#
}#
RT <- Comp_Graph_l(comp.rt$rt.mean,comp.rt$rtAdj.sd, comp.rt$Stim, comp.rt$DetailedTask, comp$Subj, paste("Two Words", "Reaction Time", sep = " "), c(650,1000),"Reaction Time (ms)",leg = TRUE)#
par(fig = c(0,1,0,0.35),mar = c(3,4,2,2), new = TRUE)#
Acc <- Comp_Graph_l(comp.Acc$Acc.mean,comp.Acc$AccAdj.sd, comp.Acc$Stim, comp.Acc$DetailedTask, comp$Subj, paste("Two Words", "Accuracy", sep = " "), c(0.7,1.05),"Accuracy")#
#
>>>>>>> Stashed changes
# Get the gtables#
gRT <- ggplotGrob(RT)#
gAcc <- ggplotGrob(Acc)#
#
# Set the widths#
gAcc$widths <- gRT$widths#
#
# Arrange the two charts.#
# The legend boxes are centered#
grid.newpage()#
<<<<<<< Updated upstream
grid.arrange(gAcc, gRT, nrow = 2, heights = c(1,2))
=======
grid.arrange(gAcc,gRT, nrow = 2, heights = c(1,2))
comp.rt <- summaryBy(rt + rtAdj ~ PicType + DetailedTask + Stim + Subj, , data = subset(comp, Acc ==1 & Match == "Match"), FUN = c(mean), na.rm = T , keep.names = T)#
#
# Show subject means#
ggplot(comp.rt,aes(x = Stim, y = rt, color = Subj, group = Subj)) + facet_wrap(~DetailedTask)+#
  geom_path()+guides(color = FALSE, group = FALSE)+ ylab("Reaction Time (ms)")+xlab("Stimulus Length")
summary(comp.rt)
library(dplyr)
comp.rt.int <- comp.rt %>%
filter(n() == 2) %>%#
  mutate(rt_diff = rt[Stim == "One Word"] - rt[Stim == "Two Words"])
comp.rt.inst
comp.rt.int
comp.rt.int <- comp.rt %>%
group_by(DetailedTask,Stim, Subj) %>%
filter(n()==2) %>%
mutate(rt_diff = rt[Stim == "One Word"] - rt[Stim == "Two Words"])
comp.rt.int
comp.rt.int <- comp.rt %>%
group_by(DetailedTask,Subj,Stim) %>%
filter(n()==2) %>%
mutate(rt_diff = rt[Stim == "One Word"] - rt[Stim == "Two Words"])
comp.rt.int
comp.rt.int <- comp.rt %>%
comp.rt.int
summary(comp.rt.int)
summary(comp.rt)
comp.rt.int <- comp.rt %>%
group_by(DetailedTask,Subj,Stim)
summary(comp.rt.int)
comp.rt.int <- comp.rt %>%
group_by(Subj,Stim)
summary(comp.rt.int)
group_by(DetailedTask,Subj,Stim)
comp.rt.int <- comp.rt %>%
group_by(Subj,Stim) %>%
filter(n()==2) %>%
mutate(rt_diff = rt[Stim == "One Word"] - rt[Stim == "Two Words"])
summary(comp.rt.int)
comp.rt.int <- comp.rt %>%
group_by(Subj,Stim) %>%
filter(n()==2)
summary(comp.rt.int)
comp.rt.int <- comp.rt %>%
group_by(Subj,Stim) %>%
mutate(rt_diff = rt[Stim == "One Word"] - rt[Stim == "Two Words"])
summary(comp.rt.int)
comp.rt[comp.rt$Stim == "One Word",]
comp.rt$rt[comp.rt$Stim == "One Word",]
comp.rt$rt
comp.rt.int <- comp.rt %>%
group_by(DetailedTask,Subj,Stim) %>%
summarize(mean_rt = mean(rt)) %>%
filter(n()==2)
summary(comp.rt.int)
comp.rt.int <- comp.rt %>%
group_by(rt,DetailedTask,Subj,Stim) %>%
filter(n()==2)
group_by(DetailedTask,Subj,Stim) %>%
comp.rt.int <- comp.rt %>%
group_by(rt,DetailedTask,Subj,Stim) %>%
filter(n()==2) %>%
mutate(rt_diff = rt[Stim == "One Word"] - rt[Stim == "Two Words"])
comp.rt.int
comp.rt.int <- comp.rt %>%
group_by(DetailedTask,Subj,Stim) %>%
summarize(rt = mean(rt)) %>%
filter(n()==2) %>%
mutate(rt_diff = rt[Stim == "One Word"] - rt[Stim == "Two Words"])
comp.rt.int
comp.rt.int <- comp.rt %>%
group_by(DetailedTask,Subj,Stim) %>%
filter(n()==2) %>%
summarize(rt_diff = rt[Stim == "One Word"] - rt[Stim == "Two Words"])
comp.rt.int
comp.rt.int <- comp.rt %>%#
 group_by(DetailedTask,Subj,Stim) %>%#
 summarize(rt = mean(rt)) %>%#
 filter(n()==2) %>%#
 summarize(rt_diff = rt[Stim == "One Word"] - rt[Stim == "Two Words"])
comp.rt.int
sd(comp.rt.int$rt_diff)
sd(comp.rt$rt)
sd(comp.rt.int[DetailedTask == "Matched Predictability (Pink Tree)",]$rt_diff)
sd(comp.rt.int[comp.rt.int$DetailedTask == "Matched Predictability (Pink Tree)",]$rt_diff)
sd(comp.rt.int[comp.rt.int$DetailedTask == "MisMatched Predictability (Pink Tree)",]$rt_diff)
sd(comp.rt.int[comp.rt.int$DetailedTask == "Mismatched Predictability (Pink Tree)",]$rt_diff)
sd(comp.rt[comp.rt$DetailedTask == "Mismatched Predictability (Pink Tree)",]$rt)
192.79/42.01
sd(comp.rt[comp.rt$DetailedTask == "Mismatched Predictability (Pink Tree)" & Stim == "One Word",]$rt)
sd(comp.rt[comp.rt$DetailedTask == "Mismatched Predictability (Pink Tree)" & comp.rt$Stim == "One Word",]$rt)
209.29/42.01
>>>>>>> Stashed changes
